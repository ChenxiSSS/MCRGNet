{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A demo for pretraining with our CAE tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)\n",
    "\n",
    "import ConvAE\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_raw = []\n",
    "num_grp = 8\n",
    "for i in range(num_grp):\n",
    "    fname = '../../BH12/data/BH12_171020/sample-BH-120-120-10-c3-gr{0}.pkl'.format(i)\n",
    "    with open(fname, 'rb') as fp:\n",
    "        datadict = pickle.load(fp)\n",
    "        X_raw.append(datadict['data'])\n",
    "    time.sleep(3)\n",
    "\n",
    "# Combine and normalization\n",
    "X_pre = np.vstack(X_raw)\n",
    "del(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 120\n",
    "X_tr = X_pre.reshape(-1,rs,rs,1).astype('float32')\n",
    "\n",
    "# Construct the network\n",
    "numclass = 2\n",
    "encode_nodes = 64\n",
    "cae = ConvAE.ConvAE(input_shape=X_tr.shape,\n",
    "            kernel_size=[3,3,3,3,3],\n",
    "            kernel_num = [8,8,16,32,32],\n",
    "            fc_nodes=[], encode_nodes=encode_nodes,\n",
    "            padding=('SAME','SAME'),\n",
    "            stride=(2,2),\n",
    "            numclass = numclass)\n",
    "cae.cae_build()\n",
    "cae.cnn_build(learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-13: 13:02:23] Training parameters\n",
      "\n",
      "[2017-12-13: 13:02:23] Epochs: 20\tLearning rate: 0.00\n",
      "\n",
      "[2017-12-13: 13:02:23] Batch size: 100\tDrop rate: 0.50\n",
      "\n",
      "[2017-12-13: 13:02:54] Epoch: 001\tTraining loss: 0.001262\tValidation loss: 0.001155\n",
      "[2017-12-13: 13:03:24] Epoch: 002\tTraining loss: 0.001126\tValidation loss: 0.001048\n",
      "[2017-12-13: 13:03:55] Epoch: 003\tTraining loss: 0.000893\tValidation loss: 0.000592\n",
      "[2017-12-13: 13:04:25] Epoch: 004\tTraining loss: 0.000522\tValidation loss: 0.000452\n",
      "[2017-12-13: 13:04:56] Epoch: 005\tTraining loss: 0.000448\tValidation loss: 0.000415\n",
      "[2017-12-13: 13:05:25] Epoch: 006\tTraining loss: 0.000418\tValidation loss: 0.000396\n",
      "[2017-12-13: 13:05:56] Epoch: 007\tTraining loss: 0.000399\tValidation loss: 0.000382\n",
      "[2017-12-13: 13:06:27] Epoch: 008\tTraining loss: 0.000386\tValidation loss: 0.000372\n",
      "[2017-12-13: 13:06:57] Epoch: 009\tTraining loss: 0.000378\tValidation loss: 0.000370\n",
      "[2017-12-13: 13:07:28] Epoch: 010\tTraining loss: 0.000371\tValidation loss: 0.000362\n",
      "[2017-12-13: 13:07:59] Epoch: 011\tTraining loss: 0.000366\tValidation loss: 0.000358\n",
      "[2017-12-13: 13:08:30] Epoch: 012\tTraining loss: 0.000361\tValidation loss: 0.000358\n",
      "[2017-12-13: 13:09:01] Epoch: 013\tTraining loss: 0.000358\tValidation loss: 0.000354\n",
      "[2017-12-13: 13:09:31] Epoch: 014\tTraining loss: 0.000356\tValidation loss: 0.000349\n",
      "[2017-12-13: 13:10:02] Epoch: 015\tTraining loss: 0.000353\tValidation loss: 0.000347\n",
      "[2017-12-13: 13:10:32] Epoch: 016\tTraining loss: 0.000351\tValidation loss: 0.000346\n",
      "[2017-12-13: 13:11:03] Epoch: 017\tTraining loss: 0.000349\tValidation loss: 0.000347\n",
      "[2017-12-13: 13:11:34] Epoch: 018\tTraining loss: 0.000348\tValidation loss: 0.000344\n",
      "[2017-12-13: 13:12:05] Epoch: 019\tTraining loss: 0.000346\tValidation loss: 0.000343\n",
      "[2017-12-13: 13:12:35] Epoch: 020\tTraining loss: 0.000345\tValidation loss: 0.000341\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "droprate = 0.5\n",
    "cae.cae_train(data=X_tr, num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "              batch_size=batch_size, droprate=droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pre-trained network\n",
    "foldname = \"./net-pretrained\"\n",
    "name = \"pretrained.pkl\"\n",
    "netname = \"model-pretrain.ckpt\"\n",
    "if os.path.exists(foldname):\n",
    "    os.system(\"rm -r %s\" % (foldname))\n",
    "os.mkdir(foldname)\n",
    "cae.cae_save(namepath=os.path.join(foldname, name),\n",
    "             netpath=os.path.join(foldname, netname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 120, 120, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzx/.local/lib/python3.5/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAACNCAYAAACEyG9XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f0e8516a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Show the reconstructed results\n",
    "n_examples = 10\n",
    "idx = np.random.permutation(len(X_tr))\n",
    "test_xs = X_tr[idx[0:n_examples],:,:,:].astype('float32')\n",
    "\n",
    "recon = cae.cae_test(img=test_xs)\n",
    "print(recon.shape)\n",
    "\n",
    "def gen_norm(img):\n",
    "    return (img-img.min())/(img.max() - img.min())\n",
    "\n",
    "fig, axs = plt.subplots(2, n_examples, figsize=(n_examples, 2))\n",
    "for example_i in range(n_examples):\n",
    "    # raw\n",
    "    axs[0][example_i].imshow(\n",
    "        np.reshape(test_xs[example_i, :], (rs, rs)), cmap='gray')\n",
    "    axs[0][example_i].axis('off')\n",
    "    # learned\n",
    "    axs[1][example_i].imshow(\n",
    "        np.reshape(\n",
    "            np.reshape(recon[example_i, ...], (rs**2,)),\n",
    "            (rs, rs)), cmap='gray')\n",
    "    axs[1][example_i].axis('off')\n",
    "\n",
    "fig.show()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
